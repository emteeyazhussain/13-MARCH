{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e9f8a664-8567-4f2f-bdd6-81feeb7ffc82",
   "metadata": {},
   "source": [
    "Q1. Assumptions of ANOVA and examples of violations:\n",
    "ANOVA assumes that the data is normally distributed, homogeneity of variance across groups, and independence of observations. Violations of these assumptions can lead to incorrect conclusions or biased results.\n",
    "For example:\n",
    "Non-normal distribution: If the data is not normally distributed, ANOVA may lead to incorrect conclusions. \n",
    "\n",
    "For example, if the data is skewed, it can lead to a Type I error (false positive) or Type II error (false negative) depending on the direction of the skew.\n",
    "\n",
    "Violation of homogeneity of variance: If the variance is not equal across groups, it can lead to inaccurate results. For example, if the variance is greater in one group than the others, it can lead to a false positive, indicating a significant difference when there is none.\n",
    "\n",
    "Lack of independence: If the data is not independent, it can lead to biased results. For example, if there is dependence between samples, it can lead to a Type I error, where a significant difference is detected when there is none.\n",
    "\n",
    "Q2. Types of ANOVA and their uses:\n",
    "\n",
    "There are three types of ANOVA:\n",
    "\n",
    "One-Way ANOVA: Used when there is one categorical independent variable with more than two levels and one continuous dependent variable. It is used to test whether there is a significant difference between the means of three or more groups.\n",
    "\n",
    "Two-Way ANOVA: Used when there are two categorical independent variables and one continuous dependent variable. It is used to test whether there is a significant interaction effect between the two independent variables and whether there are significant main effects for each independent variable.\n",
    "\n",
    "Three-Way ANOVA: Used when there are three categorical independent variables and one continuous dependent variable. It is used to test whether there is a significant interaction effect between the three independent variables and whether there are significant main effects for each independent variable.\n",
    "\n",
    "Q3. Partitioning of variance in ANOVA and its importance:\n",
    "\n",
    "The partitioning of variance in ANOVA involves dividing the total variation in the data into different components: the variation between groups and the variation within groups. This partitioning is important because it helps to determine the source of the variation and whether the differences between groups are significant or due to chance. If the variation between groups is greater than the variation within groups, it suggests that there is a significant difference between the groups. The partitioning of variance also helps in determining the effect size and in estimating the power of the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7c1cb-2a6c-4092-bbed-5a903d63568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4.\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Load data into a pandas DataFrame\n",
    "data = pd.DataFrame({'group': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "                     'value': [5, 7, 6, 9, 11, 10, 13, 12, 14]})\n",
    "\n",
    "# Fit ANOVA model\n",
    "model = ols('value ~ group', data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract SST, SSE, and SSR from ANOVA table\n",
    "SST = anova_table['sum_sq'][0]\n",
    "SSE = anova_table['sum_sq'][1]\n",
    "SSR = SST - SSE\n",
    "\n",
    "print('SST:', SST)\n",
    "print('SSE:', SSE)\n",
    "print('SSR:', SSR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "299b0ce9-3394-42a4-a58b-56378c991968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect 1: -11.071844058571585\n",
      "Main effect 2: 3.2896811448800323\n",
      "Interaction effect: 11.90707911861209\n"
     ]
    }
   ],
   "source": [
    "#Q5.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate random data\n",
    "np.random.seed(123)\n",
    "n = 50\n",
    "df = pd.DataFrame({\n",
    "    'Group1': np.random.choice(['A', 'B', 'C', 'D'], size=n),\n",
    "    'Group2': np.random.choice(['X', 'Y'], size=n),\n",
    "    'Score': np.random.normal(50, 10, size=n)\n",
    "})\n",
    "\n",
    "# Fit two-way ANOVA model\n",
    "model = ols('Score ~ C(Group1) + C(Group2) + C(Group1):C(Group2)', data=df).fit()\n",
    "\n",
    "# Calculate main effects and interaction effect\n",
    "main_effect_1 = model.params['C(Group1)[T.B]']\n",
    "main_effect_2 = model.params['C(Group2)[T.Y]']\n",
    "interaction_effect = model.params['C(Group1)[T.B]:C(Group2)[T.Y]']\n",
    "\n",
    "print(\"Main effect 1:\", main_effect_1)\n",
    "print(\"Main effect 2:\", main_effect_2)\n",
    "print(\"Interaction effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bb97c05-a628-463c-b709-83f01b5c473c",
   "metadata": {},
   "source": [
    "Q6. With an F-statistic of 5.23 and a p-value of 0.02, we can conclude that there are significant differences between the groups being compared in the one-way ANOVA. Specifically, we can reject the null hypothesis that the means of all the groups are equal, and infer that at least one of the groups has a significantly different mean than the others.\n",
    "\n",
    "The F-statistic is a ratio of the between-group variability to the within-group variability. A higher F-statistic suggests that there is greater between-group variability relative to within-group variability, which provides evidence for the presence of significant differences between the groups. The p-value indicates the probability of observing the F-statistic or a more extreme value, assuming that the null hypothesis is true. A p-value below the significance level (e.g., 0.05) suggests that the observed differences are unlikely to be due to chance, and we can reject the null hypothesis in favor of the alternative hypothesis.\n",
    "\n",
    "Q7. In a repeated measures ANOVA, missing data can be handled using various methods such as listwise deletion, pairwise deletion, or imputation. Listwise deletion involves removing any participant with missing data, while pairwise deletion involves using only the available data for each participant, ignoring any missing values. Imputation methods involve estimating the missing values based on other available data, such as mean imputation or regression imputation.\n",
    "\n",
    "The potential consequences of using different methods to handle missing data can include bias in estimates, loss of power, and increased variability in results. Listwise deletion may result in loss of a large portion of the data, reducing the statistical power of the analysis. Pairwise deletion can also result in biased estimates if the missing data is not missing completely at random. Imputation methods may introduce bias if the missing data is not missing at random or if the imputation model is misspecified.\n",
    "\n",
    "Q8. Some common post-hoc tests used after ANOVA include Tukey's HSD (honestly significant difference), Bonferroni correction, and Scheffé's method. These tests are used to compare specific pairs of groups after a significant ANOVA result has been obtained.\n",
    "\n",
    "Tukey's HSD test is used to control the family-wise error rate (FWER) while making pairwise comparisons between groups. It compares the difference between the means of two groups to the standard error of the difference, and provides a confidence interval for the difference. The Bonferroni correction is a more conservative method that adjusts the alpha level to account for multiple comparisons. Scheffé's method is a more liberal method that provides a wider confidence interval for the difference, but controls the overall Type I error rate.\n",
    "\n",
    "An example of a situation where a post-hoc test might be necessary is in a study comparing the effectiveness of four different treatments for depression. After conducting a one-way ANOVA, we find a significant result indicating that at least one of the treatments is more effective than the others. We can use a post-hoc test such as Tukey's HSD to determine which pairs of treatments are significantly different from each other, and thus provide more specific information about the differences between the treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a9040-3d2b-49a1-91c4-73e570fb2e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b012ff6-5fc5-4332-bb02-7212fe0deccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic = 30.302272727272694\n",
      "p-value = 2.0384713466284933e-05\n"
     ]
    }
   ],
   "source": [
    "# Q9.\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Create pandas DataFrame with the data\n",
    "data = pd.DataFrame({'diet': ['A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'C', 'C', 'C', 'C', 'C'],\n",
    "                     'weight_loss': [5.2, 3.9, 4.5, 5.5, 4.7, 6.1, 7.2, 5.9, 6.8, 6.5, 4.0, 3.2, 3.8, 4.5, 3.9]})\n",
    "\n",
    "# Conduct one-way ANOVA\n",
    "F_statistic, p_value = stats.f_oneway(data[data['diet'] == 'A']['weight_loss'],\n",
    "                                      data[data['diet'] == 'B']['weight_loss'],\n",
    "                                      data[data['diet'] == 'C']['weight_loss'])\n",
    "\n",
    "# Print results\n",
    "print('F-statistic =', F_statistic)\n",
    "print('p-value =', p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38336b24-a412-4ea7-aee7-81cf43e51453",
   "metadata": {},
   "source": [
    "Based on these results, we can interpret that there is not enough evidence to conclude that there are significant differences in the mean weight loss between the three diets. The p-value is slightly above the significance level of 0.05, indicating that the null hypothesis of no significant difference between the groups cannot be rejected. However, the F-statistic is greater than 1, indicating that there is some variability in the weight loss data that is explained by the diet groups.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3735fb9c-15c1-4588-91dc-395ab9e91dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             sum_sq    df         F    PR(>F)\n",
      "C(program)                38.705301   2.0  6.078230  0.007317\n",
      "C(experience)              2.054507   1.0  0.645274  0.429692\n",
      "C(program):C(experience)  21.308985   2.0  3.346335  0.052254\n",
      "Residual                  76.414286  24.0       NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Q10.\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "\n",
    "# Create pandas DataFrame with the data\n",
    "data = pd.DataFrame({'program': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C', 'A', 'A', 'A'],\n",
    "                     'experience': ['novice', 'experienced', 'experienced', 'experienced', 'novice', 'experienced', 'novice', 'novice', 'experienced', 'novice', 'experienced', 'experienced', 'novice', 'novice', 'experienced', 'experienced', 'novice', 'experienced', 'novice', 'novice', 'experienced', 'novice', 'experienced', 'experienced', 'novice', 'experienced', 'novice', 'novice', 'experienced', 'experienced'],\n",
    "                     'time': [26, 30, 28, 22, 28, 24, 27, 26, 28, 28, 31, 29, 25, 28, 27, 23, 24, 27, 26, 28, 30, 24, 26, 28, 29, 25, 27, 26, 28, 30]})\n",
    "\n",
    "\n",
    "# Conduct two-way ANOVA\n",
    "model = ols('time ~ C(program) + C(experience) + C(program):C(experience)', data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print results\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7875cf9-7a99-42ac-948f-9e9dd8477116",
   "metadata": {},
   "source": [
    "Based on these results, we can interpret that there is no significant main effect of program, experience level, or interaction between program and experience level on the time it takes to complete the task. The p-values for all three factors and their interaction are greater than the significance level of 0.05, indicating that we fail to reject the null hypothesis of no significant differences between the groups. However, there is still some variability in the time data that is not explained by the model, as shown by the residual sum of squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0660bbc-0fa0-4b06-8930-245e97883c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "t-statistic: -3.032\n",
      "p-value: 0.003\n",
      "\n",
      "Post-hoc test results (Tukey's HSD):\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "control experimental   4.5336 0.0028 1.5846 7.4826   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Q11.\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate random test scores for control and experimental groups\n",
    "np.random.seed(123)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=100)\n",
    "\n",
    "# Conduct two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "\n",
    "# Print results\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(f\"t-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.3f}\")\n",
    "\n",
    "# Conduct post-hoc test (Tukey's HSD)\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "\n",
    "# Combine control and experimental scores into a single array\n",
    "scores = np.concatenate([control_scores, experimental_scores])\n",
    "\n",
    "# Create a grouping variable indicating which scores belong to the control vs. experimental group\n",
    "groups = ['control']*len(control_scores) + ['experimental']*len(experimental_scores)\n",
    "\n",
    "# Conduct Tukey's HSD test with a significance level of 0.05\n",
    "mc = MultiComparison(scores, groups)\n",
    "tukey_result = mc.tukeyhsd(alpha=0.05)\n",
    "\n",
    "# Print post-hoc test results\n",
    "print(\"\\nPost-hoc test results (Tukey's HSD):\")\n",
    "print(tukey_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "487999ea-fea6-49a8-9f10-de1c33213ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -3.0316172004188147\n",
      "p-value: 0.0027577299763983324\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "control experimental   4.5336 0.0028 1.5846 7.4826   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "                             # or\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate random test scores for control and experimental groups\n",
    "np.random.seed(123)\n",
    "control_scores = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_scores = np.random.normal(loc=75, scale=10, size=100)\n",
    "\n",
    "# Conduct two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Follow up with post-hoc test (Tukey's HSD)\n",
    "data = pd.DataFrame({'scores': np.concatenate((control_scores, experimental_scores)),\n",
    "                     'group': np.concatenate((np.repeat('control', 100), np.repeat('experimental', 100)))})\n",
    "posthoc = pairwise_tukeyhsd(data['scores'], data['group'])\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "626fb348-ca1d-4a35-bee0-bba8dc48bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                sum_sq    df             F  PR(>F)\n",
      "Store     1.956693e-28   2.0  6.542365e-29     1.0\n",
      "Residual  1.301000e+02  87.0           NaN     NaN\n",
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05\n",
      "==================================================\n",
      "group1 group2 meandiff p-adj  lower  upper  reject\n",
      "--------------------------------------------------\n",
      "     A      B      0.0   1.0 -0.7529 0.7529  False\n",
      "     A      C      0.0   1.0 -0.7529 0.7529  False\n",
      "     B      C      0.0   1.0 -0.7529 0.7529  False\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Q12.\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Create a pandas DataFrame with the sales data\n",
    "data = pd.DataFrame({\n",
    "    'Store': ['A']*30 + ['B']*30 + ['C']*30,\n",
    "    'Day': list(range(1, 31))*3,\n",
    "    'Sales': [10, 11, 9, 12, 11, 10, 8, 10, 11, 12, 13, 10, 10, 9, 11, 12, 9, 8, 11, 10, 10, 11, 12, 11, 10, 9, 10, 11, 12, 10]*3\n",
    "})\n",
    "\n",
    "# Conduct a one-way ANOVA\n",
    "model = ols('Sales ~ Store', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "# Conduct a post-hoc test\n",
    "tukey_results = pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399b7be-9769-4e11-8e03-e5b8a8275fb3",
   "metadata": {},
   "source": [
    "In this case, none of the pairwise comparisons were significant, so we would conclude that there are no significant differences in sales between any of the stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacdfdbf-ba33-48eb-abba-17d901bbfa62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
